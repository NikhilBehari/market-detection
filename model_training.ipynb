{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model-training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9TBpe6vksrw"
      },
      "source": [
        "Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9FXpX9rke4N"
      },
      "source": [
        "! pip install -U segmentation-models\n",
        "! pip install q keras==2.3.1\n",
        "! pip install tensorflow==2.1.0\n",
        "! pip install Augmentor\n",
        "\n",
        "import tensorflow as tf; print(tf.__version__)\n",
        "import segmentation_models as sm\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "from keras.callbacks import History\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage as ndi\n",
        "import Augmentor\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import glob\n",
        "from natsort import natsorted\n",
        "import os\n",
        "import random\n",
        "import requests\n",
        "import zipfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLTJ8Elfk0C6"
      },
      "source": [
        "Drive Mount. Only use in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjgUwnJSkq3H",
        "outputId": "00cb8213-f7c7-4d2e-c482-fae1174e4532",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfXunLE8k7iM"
      },
      "source": [
        "Define Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fHSw2Pok5Lv"
      },
      "source": [
        "png_dim = 512\n",
        "\n",
        "mask_png_dir = \"\"\n",
        "sat_png_dir = \"\"\n",
        "\n",
        "save_path = \"\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3SHzG2EmlTv"
      },
      "source": [
        "Train and Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR4zQAR_lJqp"
      },
      "source": [
        "ground_truth_images = natsorted(glob.glob(sat_png_dir + \"/*.png\"))\n",
        "segmentation_mask_images = natsorted(glob.glob(mask_png_dir + \"/*.png\"))\n",
        "collated_images_and_masks = list(zip(ground_truth_images, \n",
        "                                    segmentation_mask_images, ))\n",
        "collated_images_and_masks\n",
        "images = [[np.asarray(Image.open(y)) for y in x] for x in collated_images_and_masks]\n",
        "\n",
        "\n",
        "p = Augmentor.DataPipeline(images)\n",
        "p.rotate90(probability=0.5)\n",
        "p.rotate270(probability=0.5)\n",
        "p.flip_left_right(probability=0.8)\n",
        "p.flip_top_bottom(probability=0.3)\n",
        "p.crop_random(probability=1, percentage_area=0.5)\n",
        "p.resize(probability=1.0, width=png_dim, height=png_dim)\n",
        "\n",
        "augmented_images = p.sample(700)\n",
        "\n",
        "r_index = 3\n",
        "f, axarr = plt.subplots(1, 2, figsize=(6,4))\n",
        "axarr[0].imshow(augmented_images[r_index][0])\n",
        "axarr[1].imshow(augmented_images[r_index][1], cmap=\"gray\")\n",
        "\n",
        "X_data = []\n",
        "Y_data = []\n",
        "for i in range(len(augmented_images)):\n",
        "  X_data.append(augmented_images[i][0])\n",
        "  Y_data.append(augmented_images[i][1])\n",
        "\n",
        "X_data = np.array(X_data)\n",
        "Y_data = np.array(Y_data)\n",
        "X_data = X_data[:,:,:,:3]\n",
        "Y_data = Y_data[:,:,:,:1]\n",
        "\n",
        "model = sm.Unet('resnet34', classes=1, encoder_weights='imagenet', activation='sigmoid')\n",
        "BACKBONE = 'resnet34'\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "# define model\n",
        "model = sm.Unet(BACKBONE, classes=1, encoder_weights='imagenet')\n",
        "model.compile(\n",
        "    'Adam',\n",
        "    loss=sm.losses.binary_crossentropy,\n",
        "    metrics=[sm.metrics.iou_score, sm.metrics.precision, sm.metrics.recall],\n",
        ")\n",
        "\n",
        "x_train = preprocess_input(X_data)\n",
        "y_train = preprocess_input(Y_data)\n",
        "detection_model = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=16,\n",
        "    epochs=60,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "model.save(save_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}